{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2007%20-%20Chains_and_Why_They_Are_Used.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZgUJsmpUCUi"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ucL9y4VoUJui"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"]=\"OPENAI_API_KEY\"\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-J9LsngZsfp"
      },
      "source": [
        "# Calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44NeYe0GXe32"
      },
      "source": [
        "## __ call __"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQn4558HUPvI",
        "outputId": "4a9ad390-aa22-42b8-f01f-9c651c1a9779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synthetic\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "     input_variables=[\"word\"],\n",
        "     template=\"What is a word to replace the following: {word}?\",\n",
        ")\n",
        "\n",
        "\n",
        "# Set the \"OPENAI_API_KEY\" environment variable before running following line.\n",
        "llm =ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template\n",
        ")\n",
        "\n",
        "# Run\n",
        "result = llm_chain.run(word=\"artificial\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jS4DWOq7OBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lGTqvJxXjMZ"
      },
      "source": [
        "## Chain run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhrI8CggVtJo",
        "outputId": "279f3026-e9d3-40cb-99e5-ae0966c5a423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Synthetic', 'Cleverness', 'android']\n"
          ]
        }
      ],
      "source": [
        "input_list = [\n",
        "    {\"word\": \"artificial\"},\n",
        "    {\"word\": \"intelligence\"},\n",
        "    {\"word\": \"robot\"}\n",
        "]\n",
        "results = [llm_chain.run(word=d[\"word\"]) for d in input_list]\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks4ej9ZXXm-E"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1BvtRiXuLg"
      },
      "source": [
        "#### Multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OX4RrRrlXvWm",
        "outputId": "d92497ef-5cd6-42b9-a2a1-a8764d7d1b87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'appliance'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "prompt_template = \"Looking at the context of '{context}'. What is a approapriate word to replace the following: {word}?\"\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(template=prompt_template, input_variables=[\"word\", \"context\"]))\n",
        "\n",
        "llm_chain.predict(word=\"fan\", context=\"object\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NpdjaLWwYQQ1",
        "outputId": "830d1bd1-6c6a-4ad2-ec6d-183135ae75fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'supporter'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "llm_chain.predict(word=\"fan\", context=\"humans\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P5gGwxClJeL"
      },
      "outputs": [],
      "source": [
        "# llm_chain.run(word=\"fan\", context=\"object\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNPOT6iAbt1l"
      },
      "source": [
        "### from string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h6T5_9k2bx_N"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Looking at the context of '{context}'. What is a approapriate word to replace the following: {word}?\"\"\"\n",
        "llm_chain = LLMChain.from_string(llm=llm, template=template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AkE6wx8Vb9Ns",
        "outputId": "146256f5-01dc-4805-f82f-74916dfaf89e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'appliance'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "llm_chain.predict(word=\"fan\", context=\"object\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRIaIXSKZu6U"
      },
      "source": [
        "# Parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aIEZWDQtZwKw",
        "outputId": "7b902741-22ea-46a9-c8ae-db606b5aab50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'synthetic, man-made, fake, simulated, imitation, faux, counterfeit, ersatz, fabricated, manufactured'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\"\"\"\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(template=template, input_variables=[], output_parser=output_parser))\n",
        "\n",
        "llm_chain.predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ18G38-aXcE",
        "outputId": "6151a9fc-764d-40fe-d5f0-7d73f41e8be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synthetic',\n",
              " 'man-made',\n",
              " 'fake',\n",
              " 'simulated',\n",
              " 'imitation',\n",
              " 'faux',\n",
              " 'ersatz',\n",
              " 'fabricated',\n",
              " 'counterfeit',\n",
              " 'pseudo']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "llm_chain.predict_and_parse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b8_oGlAcx3F"
      },
      "source": [
        "# Conversational Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTYpcUktae6w",
        "outputId": "1068f5bc-1219-438d-99ec-02c41dde16d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synthetic', 'man-made', 'simulated']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "template = \"\"\"List all possible words as substitute for 'artificial' as comma separated.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "\n",
        "{input}\"\"\"\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(template=template, input_variables=[\"history\", \"input\"], output_parser=output_parser),\n",
        "    memory=ConversationBufferMemory())\n",
        "\n",
        "conversation.predict_and_parse(input=\"Answer briefly. write the first 3 options.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_vgaBgeWWG",
        "outputId": "acad1bb9-dd18-421c-a349-f3d0682a9de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imitation', 'fake', 'faux', 'fabricated']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "conversation.predict_and_parse(input=\"And the next 4?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kz12V6FhjC3"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGRoPJ1xhtTE",
        "outputId": "33355fab-a47f-45db-85c5-4d0752b47e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mList all possible words as substitute for 'artificial' as comma separated.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "\n",
            "Answer briefly. write the first 3 options.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synthetic', 'man-made', 'simulated']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate(template=template, input_variables=[\"history\", \"input\"], output_parser=output_parser),\n",
        "    memory=ConversationBufferMemory(),\n",
        "    verbose=True)\n",
        "\n",
        "conversation.predict_and_parse(input=\"Answer briefly. write the first 3 options.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XI9e40ui1yX"
      },
      "source": [
        "# Sequential Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "A16wajt2hxLE"
      },
      "outputs": [],
      "source": [
        "# from langchain.chains import SimpleSequentialChain\n",
        "# overall_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs4Chc0iKaj3"
      },
      "source": [
        "# Custom Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3tCjI4DtKbTG"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "from typing import Dict, List\n",
        "\n",
        "\n",
        "class ConcatenateChain(Chain):\n",
        "    chain_1: LLMChain\n",
        "    chain_2: LLMChain\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        # Union of the input keys of the two chains.\n",
        "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
        "        return list(all_input_vars)\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        return ['concat_output']\n",
        "\n",
        "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
        "        output_1 = self.chain_1.run(inputs)\n",
        "        output_2 = self.chain_2.run(inputs)\n",
        "        return {'concat_output': output_1 + output_2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-W3ZqALLbwP",
        "outputId": "857a1351-2472-49ed-cc06-faabc4b02bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated output:\n",
            "Artificial means made or produced by human beings rather than occurring naturally. It can also refer to something that is not genuine or real.synthetic\n"
          ]
        }
      ],
      "source": [
        "prompt_1 = PromptTemplate(\n",
        "    input_variables=[\"word\"],\n",
        "    template=\"What is the meaning of the following word '{word}'?\",\n",
        ")\n",
        "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    input_variables=[\"word\"],\n",
        "    template=\"What is a word to replace the following: {word}?\",\n",
        ")\n",
        "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
        "\n",
        "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
        "concat_output = concat_chain.run(\"artificial\")\n",
        "print(f\"Concatenated output:\\n{concat_output}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}