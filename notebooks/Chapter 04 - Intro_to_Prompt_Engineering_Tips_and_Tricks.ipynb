{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2004%20-%20Intro_to_Prompt_Engineering_Tips_and_Tricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UankOoEqfvT5"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain==0.3.26 langchain-openai==0.3.23 langchain-core==0.3.66 langchain-community==0.3.26 openai==1.92.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kpnwP9Z6gAtB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"]=\"OPENAI_API_KEY\"\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0Qehe870ht2"
      },
      "source": [
        "# Story Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI()\n",
        "\n",
        "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
        "\n",
        "prompt = \"\"\"Continue the following story. Write no more than 200 words.\n",
        "\n",
        "Once upon a time, in a world where animals could speak, a courageous \\\n",
        "mouse named Benjamin decided to\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    instructions = prompt_system,\n",
        "    input= prompt,\n",
        "    max_output_tokens=200,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"Story continuation:\")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYxYtFxAQP7v",
        "outputId": "7a1996f7-1d2b-4127-9695-9cb0f35b5deb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story continuation:\n",
            "Once upon a time, in a world where animals could speak, a courageous mouse named Benjamin decided to embark on a daring adventure beyond the safety of his home. For years, he had listened to tales of the enchanted forest, where ancient trees whispered secrets and magical creatures roamed freely. Though small in size, Benjamin’s heart was filled with bravery and curiosity.\n",
            "\n",
            "One crisp morning, with a tiny satchel packed with cheese and a map drawn by an old owl, Benjamin set off. As he ventured deeper into the forest, he encountered a wise fox named Alaric, who warned him of the lurking shadows that guarded the forest’s greatest secret—a glowing crystal said to grant immense wisdom.\n",
            "\n",
            "Determined, Benjamin pressed on, navigating tangled roots and shimmering streams. Along the way, he befriended a chatty squirrel and a graceful deer, who joined him on his quest. Together, they faced challenges that tested their courage and friendship.\n",
            "\n",
            "At last, in a clearing bathed in moonlight,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGH6rUOG0i07"
      },
      "source": [
        "# Product Description"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_prompt_system = \"\"\"You are a helpful assistant whose goal is to help write \\\n",
        "product descriptions.\"\"\"\n",
        "\n",
        "product_prompt = \"\"\"Write a captivating product description for a luxurious, handcrafted\\\n",
        ", limited-edition fountain pen made from rosewood and gold.\n",
        "Write no more than 100 words.\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    instructions = product_prompt_system,\n",
        "    input= product_prompt,\n",
        "    max_output_tokens=100,\n",
        ")\n",
        "\n",
        "print(\"Product Description:\")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftyJ8wxrTafE",
        "outputId": "1a94f555-5108-4f55-f662-19808d8aa43c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Description:\n",
            "Experience timeless elegance with our handcrafted, limited-edition fountain pen, meticulously crafted from rich rosewood and gleaming gold. Each pen is a masterpiece, combining exquisite artistry with unparalleled writing precision. The smooth, flowing nib delivers an effortless writing experience, while the warm, natural hues of rosewood contrast beautifully with the luxurious gold accents. Perfect for collectors and connoisseurs, this exclusive pen embodies sophistication and exclusivity, making every word you write a statement of style and refinement. Elevate your writing ritual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmZFeTG0lQv"
      },
      "source": [
        "# Zero-Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
        "\n",
        "\n",
        "topic = \"summer\"\n",
        "\n",
        "# Format the prompt with the topic\n",
        "zero_shot_prompt = f\"Write a short poem about {topic}.\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    instructions=zero_shot_prompt_system,\n",
        "    input=zero_shot_prompt,\n",
        "    max_output_tokens=200,\n",
        ")\n",
        "\n",
        "print(\"Zero-shot poem about summer:\")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Hq3M-FVTRA",
        "outputId": "31d08be1-5b52-40f1-f7d9-77a9f72efce7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot poem about summer:\n",
            "Golden sun on skies so blue,  \n",
            "Whispers warm, the whole day through.  \n",
            "Laughter dances, breezes play,  \n",
            "Summer’s magic lights our way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwz-8Gdo0qri"
      },
      "source": [
        "# In-Context Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPLaRGsRz8uT",
        "outputId": "108216e2-0bdd-432c-d2b7-6df567e46337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-context learning poem about summer:\n",
            "Golden rays cascade,  \n",
            "Laughter dances in warm breeze,  \n",
            "Summer’s vibrant glow.\n"
          ]
        }
      ],
      "source": [
        "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
        "\n",
        "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
        "\n",
        "examples = {\n",
        "    \"nature\": \"\"\"Birdsong fills the air,\\nMountains high and valleys \\\n",
        "deep,\\nNature's music sweet.\"\"\",\n",
        "    \"winter\": \"\"\"Snow blankets the ground,\\nSilence is the only \\\n",
        "sound,\\nWinter's beauty found.\"\"\"\n",
        "}\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input=[\n",
        "        {\"role\": \"system\", \"content\": prompt_system},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"nature\")},\n",
        "        {\"role\": \"assistant\", \"content\": examples[\"nature\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},\n",
        "        {\"role\": \"assistant\", \"content\": examples[\"winter\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"In-context learning poem about summer:\")\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RPzI1S0r7j"
      },
      "source": [
        "# Few Shot Prompting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Examples for few-shot learning\n",
        "examples = [\n",
        "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
        "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
        "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
        "]\n",
        "\n",
        "# Template for formatting each example\n",
        "example_formatter_template = \"\"\"\n",
        "Color: {color}\n",
        "Emotion: {emotion}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"emotion\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "# Few-shot prompt template\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Here are some examples of colors and the emotions associated with them:\",\n",
        "    suffix=\"Now, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\",\n",
        ")\n",
        "\n",
        "# Chain using LCEL (LangChain Expression Language)\n",
        "chain = few_shot_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain with the input\n",
        "response = chain.invoke({\"input\": \"purple\"})\n",
        "\n",
        "print( response.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_IlqOxLX7V5",
        "outputId": "5929a542-4ccd-4704-c386-4e4d1c315e93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color: purple  \n",
            "Emotion: creativity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1cEIdTO0vi2"
      },
      "source": [
        "# Role Prompting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Prompt template\n",
        "template = \"\"\"\n",
        "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
        "What's a cool song title for a song about {theme} in the year {year}?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"theme\", \"year\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Chain using LCEL (LangChain Expression Language)\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Input data for the prompt\n",
        "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
        "\n",
        "# Run the chain to get the AI-generated song title\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "print(\"Theme: interstellar travel\")\n",
        "print(\"Year: 3030\")\n",
        "print(\"AI-generated song title:\", response.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odLaUl67je6P",
        "outputId": "5ac3de41-f6cf-4924-c85d-7a27e9771e2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theme: interstellar travel\n",
            "Year: 3030\n",
            "AI-generated song title: How about **\"Quantum Drift: Voyage Beyond the Stars\"**? It captures the futuristic vibe and the essence of interstellar travel in the year 3030!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain Prompting"
      ],
      "metadata": {
        "id": "BnTL63Z2HLPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Prompt 1\n",
        "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
        "\n",
        "# Chain for the first prompt\n",
        "chain_question = prompt_question | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.invoke({})\n",
        "\n",
        "# Extract the scientist's name from the response\n",
        "scientist = response_question.strip()\n",
        "\n",
        "# Chain for the second prompt\n",
        "chain_fact = prompt_fact | llm | StrOutputParser()\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"scientist\": scientist}\n",
        "\n",
        "# Run the chain for the second prompt\n",
        "response_fact = chain_fact.invoke(input_data)\n",
        "\n",
        "print(\"Scientist:\", scientist)\n",
        "print(\"Fact:\", response_fact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arm5MTPNjz8z",
        "outputId": "463e73a0-8084-4a38-ec49-6fae761926a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scientist: Answer: Albert Einstein\n",
            "Fact: Albert Einstein's theory of general relativity is a fundamental theory of gravitation that describes gravity not as a force, but as a curvature of spacetime caused by the presence of mass and energy. It explains how massive objects like stars and planets warp the fabric of spacetime, influencing the motion of other objects and the path of light. This theory has been confirmed by numerous experiments and observations and is essential for understanding phenomena such as black holes, gravitational waves, and the expansion of the universe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErdKr6EI1Do1"
      },
      "source": [
        "# Bad Prompt Practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UNsOOLC2gkfJ",
        "outputId": "828892b1-2f7a-4e7a-da56-e07996840270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me something about dogs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "template = \"Tell me something about {topic}.\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt.format(topic=\"dogs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOByBkJVhaBL",
        "outputId": "ba7771ba-e95b-49db-cf28-46502857955a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scientist: Answer: Albert Einstein\n",
            "Fact: Albert Einstein, one of the most famous physicists in history, developed the theory of relativity, which revolutionized our understanding of space, time, and gravity. Interestingly, despite his groundbreaking work in physics, Einstein was also a passionate advocate for civil rights and was offered the presidency of Israel in 1952, which he declined.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Prompt 1\n",
        "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
        "\n",
        "# Create the chain for the first prompt\n",
        "chain_question = prompt_question | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.invoke({})\n",
        "\n",
        "# Extract the scientist's name from the response\n",
        "scientist = response_question.strip()\n",
        "\n",
        "# Create the chain for the second prompt\n",
        "chain_fact = prompt_fact | llm | StrOutputParser()\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"scientist\": scientist}\n",
        "\n",
        "# Run the chain for the second prompt\n",
        "response_fact = chain_fact.invoke(input_data)\n",
        "\n",
        "print(\"Scientist:\", scientist)\n",
        "print(\"Fact:\", response_fact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKzhyWSEiG9H",
        "outputId": "790c298c-7453-4c43-865a-3f6e3e29c40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some musical genres include:\n",
            "\n",
            "- Pop\n",
            "- Rock\n",
            "- Jazz\n",
            "- Classical\n",
            "- Hip Hop\n",
            "- Country\n",
            "- Blues\n",
            "- Electronic\n",
            "- Reggae\n",
            "- Metal\n",
            "- R&B (Rhythm and Blues)\n",
            "- Folk\n",
            "- Punk\n",
            "- Soul\n",
            "- Disco\n",
            "\n",
            "Each genre has its own unique style, history, and cultural significance.\n",
            "Genres: jazz pop rock\n",
            "Fact: Jazz, pop, and rock are distinct musical styles that each offer unique expressions and cultural influences. They vary in rhythm, instrumentation, and emotional tone, reflecting different artistic approaches and audience experiences. Each genre has contributed significantly to the evolution of modern music and continues to inspire creativity across the world.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Prompt 1\n",
        "template_question = \"\"\"What are some musical genres?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
        "\n",
        "# Create the chain for the first prompt\n",
        "chain_question = prompt_question | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.invoke({})\n",
        "\n",
        "print(response_question)\n",
        "\n",
        "# Assign three hardcoded genres\n",
        "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
        "\n",
        "# Create the chain for the second prompt\n",
        "chain_fact = prompt_fact | llm | StrOutputParser()\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
        "\n",
        "# Run the chain for the second prompt\n",
        "response_fact = chain_fact.invoke(input_data)\n",
        "\n",
        "print(\"Genres:\", genre1, genre2, genre3)\n",
        "print(\"Fact:\", response_fact)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MVvNNQA1M2F"
      },
      "source": [
        "# Tips for Effective Prompting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What's the secret to happiness?\",\n",
        "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
        "    }, {\n",
        "        \"query\": \"How can I become more productive?\",\n",
        "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# Create the chain for the few-shot prompt template\n",
        "chain = few_shot_prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Define the user query\n",
        "user_query = \"What are some tips for improving communication skills?\"\n",
        "\n",
        "# Run the chain for the user query\n",
        "response = chain.invoke({\"query\": user_query})\n",
        "\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"AI Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22vYU8oXNo3n",
        "outputId": "96539fbc-10de-4e21-cb0f-755cbaa62d4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: What are some tips for improving communication skills?\n",
            "AI Response: To improve communication skills, focus on active listening, practice clear and concise expression, and be mindful of nonverbal cues. Additionally, seek feedback and engage in regular conversations to build confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kXPDhFq4i5Ep",
        "outputId": "42cf07df-fdfa-4811-c877-66fd09eb6156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vague prompt result:\n",
            "Sure! Please provide the sales data or the document you'd like me to analyze, and I'll give you insights based on the sales numbers.\n",
            "\n",
            "No format guidance result:\n",
            "As of my knowledge cutoff in June 2024, here is an overview of Apple Inc.'s recent financial performance:\n",
            "\n",
            "### Revenue and Profitability\n",
            "Apple has consistently demonstrated strong financial performance, driven by its diverse product lineup including the iPhone, iPad, Mac, Apple Watch, and services such as the App Store, Apple Music, and iCloud. In its fiscal year 2023, Apple reported:\n",
            "\n",
            "- **Revenue:** Approximately $383 billion, marking a steady increase compared to previous years.\n",
            "- **Net Income:** Around $100 billion, reflecting strong profitability and efficient cost management.\n",
            "- **Gross Margin:** Typically around 40-42%, indicating healthy margins on its products and services.\n",
            "\n",
            "### Key Drivers\n",
            "- **iPhone Sales:** The iPhone remains Apple's largest revenue contributor, with the latest models continuing to perform well globally.\n",
            "- **Services Segment:** This segment has shown rapid growth, contributing over 20% of total revenue, driven by subscriptions and digital content.\n",
            "- **Wearables and Accessories:** Products like the Apple Watch and AirPods have also seen significant sales growth.\n",
            "\n",
            "### Cash Flow and Balance Sheet\n",
            "Apple maintains a robust balance sheet with substantial cash reserves exceeding $50 billion, enabling ongoing investment in research and development, acquisitions, and shareholder returns through dividends and stock buybacks.\n",
            "\n",
            "### Market Performance\n",
            "Apple remains one of the most valuable companies globally, with a market capitalization often exceeding $2.5 trillion. Its stock performance has generally outpaced the broader market, reflecting investor confidence in its innovation and financial stability.\n",
            "\n",
            "### Challenges and Outlook\n",
            "- **Supply Chain:** Apple has faced some supply chain constraints but continues to manage them effectively.\n",
            "- **Regulatory Environment:** Increasing scrutiny over privacy, App Store policies, and antitrust issues could impact future operations.\n",
            "- **Innovation:** Continued investment in new technologies such as augmented reality, artificial intelligence, and electric vehicles is expected to drive future growth.\n",
            "\n",
            "If you want the most current quarterly data or specific financial metrics, I recommend checking Apple's latest earnings reports or trusted financial news sources.\n"
          ]
        }
      ],
      "source": [
        "# Bad Prompt Practices\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# BAD EXAMPLE 1: Vague and context-less\n",
        "template_vague = \"Analyze this and give me insights about {data}.\"\n",
        "prompt_vague = PromptTemplate(\n",
        "    input_variables=[\"data\"],\n",
        "    template=template_vague,\n",
        ")\n",
        "\n",
        "# BAD EXAMPLE 2: Conflicting instructions\n",
        "template_conflict = \"\"\"Write a detailed comprehensive analysis of {topic} but keep it brief and don't include too much information. Be specific but also general.\"\"\"\n",
        "prompt_conflict = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template_conflict,\n",
        ")\n",
        "\n",
        "# BAD EXAMPLE 3: No output format guidance\n",
        "template_no_format = \"Tell me about {company} financial performance.\"\n",
        "prompt_no_format = PromptTemplate(\n",
        "    input_variables=[\"company\"],\n",
        "    template=template_no_format,\n",
        ")\n",
        "\n",
        "# BAD EXAMPLE 4: Overly complex single prompt\n",
        "template_complex = \"\"\"Given {product}, analyze the market, competitors, pricing strategy, customer segments, marketing channels, potential risks, growth opportunities, financial projections, and implementation timeline while also considering regulatory requirements and technological trends.\"\"\"\n",
        "prompt_complex = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=template_complex,\n",
        ")\n",
        "\n",
        "# BAD EXAMPLE 5: Assumptions without context\n",
        "template_assumptions = \"Fix the obvious issues with {code} and optimize it.\"\n",
        "prompt_assumptions = PromptTemplate(\n",
        "    input_variables=[\"code\"],\n",
        "    template=template_assumptions,\n",
        ")\n",
        "\n",
        "# Example of running bad prompts\n",
        "chain_vague = prompt_vague | llm | StrOutputParser()\n",
        "response_vague = chain_vague.invoke({\"data\": \"sales numbers\"})\n",
        "\n",
        "print(\"Vague prompt result:\")\n",
        "print(response_vague)\n",
        "\n",
        "chain_no_format = prompt_no_format | llm | StrOutputParser()\n",
        "response_no_format = chain_no_format.invoke({\"company\": \"Apple\"})\n",
        "\n",
        "print(\"\\nNo format guidance result:\")\n",
        "print(response_no_format)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}