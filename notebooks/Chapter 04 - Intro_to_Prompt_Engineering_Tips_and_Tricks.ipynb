{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwvBKVBDkLtkgt+P/H+Iok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2004%20-%20Intro_to_Prompt_Engineering_Tips_and_Tricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UankOoEqfvT5",
        "outputId": "149e4343-f6dc-4277-e564-84249ceb229e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='<OPENAI_API_KEY>'\" > .env\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpnwP9Z6gAtB",
        "outputId": "e61fabbd-9c0f-4499-b549-5854e307d444"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Story Generation"
      ],
      "metadata": {
        "id": "Z0Qehe870ht2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
        "\n",
        "prompt = \"\"\"Continue the following story. Write no more than 50 words.\n",
        "\n",
        "Once upon a time, in a world where animals could speak, a courageous \\\n",
        "mouse named Benjamin decided to\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt_system},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr7-jcJl0J6Y",
        "outputId": "f0021277-633c-42e7-8aa7-27a1bb83482f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embark on a quest to find the mystical cheese of legends. Along the way, he encountered clever challenges and made unlikely friends with a wise old owl and a mischievous squirrel. The journey tested his bravery and determination, but Benjamin never gave up.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Product Description"
      ],
      "metadata": {
        "id": "HGH6rUOG0i07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt_system = \"\"\"You are a helpful assistant whose goal is to help write \\\n",
        "product descriptions.\"\"\"\n",
        "\n",
        "prompt = \"\"\"Write a captivating product description for a luxurious, handcrafted\\\n",
        ", limited-edition fountain pen made from rosewood and gold.\n",
        "Write no more than 50 words.\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt_system},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9fWIO_00EwL",
        "outputId": "c4aaa71c-7c1f-497a-aeae-0a85f301dab3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indulge in the refined elegance of our limited-edition fountain pen, meticulously handcrafted from lustrous rosewood and accented with opulent gold detailing. This exquisite piece of artistry embodies sophistication and luxury, destined to elevate your writing experience to new heights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-Shot Prompting"
      ],
      "metadata": {
        "id": "itmZFeTG0lQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
        "\n",
        "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt_system},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swbFmvyh0Bbu",
        "outputId": "ffc30ef3-4b04-4ebc-ab1e-1583556714db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summer arrives with a golden glow,\n",
            "Warm sun on skin, a gentle breeze to show,\n",
            "Days filled with laughter, evenings aglow,\n",
            "In this season of bliss, memories flow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Context Learning"
      ],
      "metadata": {
        "id": "Pwz-8Gdo0qri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
        "\n",
        "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
        "\n",
        "examples = {\n",
        "    \"nature\": \"\"\"Birdsong fills the air,\\nMountains high and valleys \\\n",
        "deep,\\nNature's music sweet.\"\"\",\n",
        "    \"winter\": \"\"\"Snow blankets the ground,\\nSilence is the only \\\n",
        "sound,\\nWinter's beauty found.\"\"\"\n",
        "}\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": prompt_system},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"nature\")},\n",
        "        {\"role\": \"assistant\", \"content\": examples[\"nature\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},\n",
        "        {\"role\": \"assistant\", \"content\": examples[\"winter\"]},\n",
        "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPLaRGsRz8uT",
        "outputId": "69ad4cfc-c5f1-4a6e-ab71-f60924db5ffe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Golden sun up high,\n",
            "Laughter echoes in the sky,\n",
            "Summer days fly by.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few Shot Prompting"
      ],
      "metadata": {
        "id": "48RPzI1S0r7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "\n",
        "examples = [\n",
        "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
        "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
        "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
        "]\n",
        "\n",
        "example_formatter_template = \"\"\"\n",
        "Color: {color}\n",
        "Emotion: {emotion}\\n\n",
        "\"\"\"\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"emotion\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"\"\"Here are some examples of colors and the emotions associated with \\\n",
        "them:\\n\\n\"\"\",\n",
        "    suffix=\"\"\"\\n\\nNow, given a new color, identify the emotion associated with \\\n",
        "it:\\n\\nColor: {input}\\nEmotion:\"\"\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\",\n",
        ")\n",
        "\n",
        "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
        "\n",
        "# Create the LLMChain for the prompt\n",
        "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt,\n",
        "input_variables=[]))\n",
        "\n",
        "# Run the LLMChain to get the AI-generated emotion associated with the input\n",
        "# color\n",
        "response = chain.run({})\n",
        "\n",
        "print(\"Color: purple\")\n",
        "print(\"Emotion:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_coZjXhz0L1",
        "outputId": "27a5e6da-8dce-46bb-c5c9-7091d91b85a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color: purple\n",
            "Emotion: royalty or luxury\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Role Prompting"
      ],
      "metadata": {
        "id": "M1cEIdTO0vi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "\n",
        "template = \"\"\"\n",
        "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
        "What's a cool song title for a song about {theme} in the year {year}?\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"theme\", \"year\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Create the LLMChain for the prompt\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Input data for the prompt\n",
        "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
        "\n",
        "# Run the LLMChain to get the AI-generated song title\n",
        "response = chain.run(input_data)\n",
        "\n",
        "print(\"Theme: interstellar travel\")\n",
        "print(\"Year: 3030\")\n",
        "print(\"AI-generated song title:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuflOySdgCsv",
        "outputId": "2203d32c-d46d-4f93-ec5e-7094a1d7ce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theme: interstellar travel\n",
            "Year: 3030\n",
            "AI-generated song title: \n",
            "\"Journey to the Stars: 3030\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
        "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
        "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
        "]\n",
        "\n",
        "example_formatter_template = \"\"\"\n",
        "Color: {color}\n",
        "Emotion: {emotion}\\n\n",
        "\"\"\"\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"color\", \"emotion\"],\n",
        "    template=example_formatter_template,\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Here are some examples of colors and the emotions associated with them:\\n\\n\",\n",
        "    suffix=\"\\n\\nNow, given a new color, identify the emotion associated with it:\\n\\nColor: {input}\\nEmotion:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\",\n",
        ")\n",
        "\n",
        "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
        "\n",
        "# Create the LLMChain for the prompt\n",
        "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
        "\n",
        "# Run the LLMChain to get the AI-generated emotion associated with the input color\n",
        "response = chain.run({})\n",
        "\n",
        "print(\"Color: purple\")\n",
        "print(\"Emotion:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_R56C3dgK49",
        "outputId": "188de295-0d9d-496d-b4d9-f1b2c58ce684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Color: purple\n",
            "Emotion:  creativity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain Prompting"
      ],
      "metadata": {
        "id": "BTUMpai0083e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1\n",
        "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
        "\n",
        "# Create the LLMChain for the first prompt\n",
        "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
        "\n",
        "# Run the LLMChain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.run({})\n",
        "\n",
        "# Extract the scientist's name from the response\n",
        "scientist = response_question.strip()\n",
        "\n",
        "# Create the LLMChain for the second prompt\n",
        "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"scientist\": scientist}\n",
        "\n",
        "# Run the LLMChain for the second prompt\n",
        "response_fact = chain_fact.run(input_data)\n",
        "\n",
        "print(\"Scientist:\", scientist)\n",
        "print(\"Fact:\", response_fact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5ZqopkbhDsi",
        "outputId": "a842da0e-3a79-444f-bd3a-1bc754cd5eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scientist: Albert Einstein\n",
            "Fact: \n",
            "Albert Einstein's theory of general relativity is a theory of gravitation that states that the gravitational force between two objects is a result of the curvature of spacetime caused by the presence of mass and energy. It explains the phenomenon of gravity as a result of the warping of space and time by matter and energy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bad Prompt Practices"
      ],
      "metadata": {
        "id": "ErdKr6EI1Do1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Tell me something about {topic}.\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template,\n",
        ")\n",
        "prompt.format(topic=\"dogs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UNsOOLC2gkfJ",
        "outputId": "169a1488-762a-4ead-9e49-b5f1b087d9d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me something about dogs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1\n",
        "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
        "\n",
        "# Create the LLMChain for the first prompt\n",
        "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
        "\n",
        "# Run the LLMChain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.run({})\n",
        "\n",
        "# Extract the scientist's name from the response\n",
        "scientist = response_question.strip()\n",
        "\n",
        "# Create the LLMChain for the second prompt\n",
        "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"scientist\": scientist}\n",
        "\n",
        "# Run the LLMChain for the second prompt\n",
        "response_fact = chain_fact.run(input_data)\n",
        "\n",
        "print(\"Scientist:\", scientist)\n",
        "print(\"Fact:\", response_fact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOByBkJVhaBL",
        "outputId": "34ffbf6f-70a8-4f8f-d594-06181f36f8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scientist: Albert Einstein\n",
            "Fact:  Albert Einstein was a vegetarian and an advocate for animal rights. He was also a pacifist and a socialist, and he was a strong supporter of the civil rights movement. He was also a passionate violinist and a lover of sailing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt 1\n",
        "template_question = \"\"\"What are some musical genres?\n",
        "Answer: \"\"\"\n",
        "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
        "\n",
        "# Prompt 2\n",
        "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
        "Answer: \"\"\"\n",
        "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
        "\n",
        "# Create the LLMChain for the first prompt\n",
        "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
        "\n",
        "# Run the LLMChain for the first prompt with an empty dictionary\n",
        "response_question = chain_question.run({})\n",
        "\n",
        "# Assign three hardcoded genres\n",
        "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
        "\n",
        "# Create the LLMChain for the second prompt\n",
        "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
        "\n",
        "# Input data for the second prompt\n",
        "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
        "\n",
        "# Run the LLMChain for the second prompt\n",
        "response_fact = chain_fact.run(input_data)\n",
        "\n",
        "print(\"Genres:\", genre1, genre2, genre3)\n",
        "print(\"Fact:\", response_fact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKzhyWSEiG9H",
        "outputId": "25e50f68-1cec-444f-ec02-a506f73e6b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genres: jazz pop rock\n",
            "Fact: \n",
            "Jazz, pop, and rock are all genres of popular music that have been around for decades. They all have distinct sounds and styles, and have influenced each other in various ways. Jazz is often characterized by improvisation, complex harmonies, and syncopated rhythms. Pop music is typically more accessible and often features catchy melodies and hooks. Rock music is often characterized by distorted guitars, heavy drums, and powerful vocals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tips for Effective Prompting"
      ],
      "metadata": {
        "id": "4MVvNNQA1M2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What's the secret to happiness?\",\n",
        "        \"answer\": \"Finding balance in life and learning to enjoy the small moments.\"\n",
        "    }, {\n",
        "        \"query\": \"How can I become more productive?\",\n",
        "        \"answer\": \"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "life coach. The assistant provides insightful and practical advice to the users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# Create the LLMChain for the few-shot prompt template\n",
        "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
        "\n",
        "# Define the user query\n",
        "user_query = \"What are some tips for improving communication skills?\"\n",
        "\n",
        "# Run the LLMChain for the user query\n",
        "response = chain.run({\"query\": user_query})\n",
        "\n",
        "print(\"User Query:\", user_query)\n",
        "print(\"AI Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-MLn4suilQy",
        "outputId": "6b7f4c3e-981a-4744-b14c-59fcd13e82b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Query: What are some tips for improving communication skills?\n",
            "AI Response:  Practice active listening, be mindful of your body language, and be open to constructive feedback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXPDhFq4i5Ep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}