{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "esuXFO7tnYED"
      },
      "outputs": [],
      "source": [
        "!pip install -q deeplake==4.2.11 langchain==0.3.26 langchain-openai==0.3.23 langchain-core==0.3.66 langchain-deeplake==0.1.0 langchain-community==0.3.26 openai==1.92.0 tiktoken==0.8.0 python-dotenv jedi==0.19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i-4UEmugnaPa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"]=\"OPENAI_API_KEY\"\n",
        "# os.environ[\"ACTIVELOOP_TOKEN\"]=\"YOUR_ACTIVELOOP_TOKEN\"\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"]= userdata.get('ACTIVELOOP_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Initialize the chat model\n",
        "chat = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# Create the chat prompt template using modern tuple-based approach\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant that translates english to pirate.\"),\n",
        "    (\"human\", \"Hi\"),\n",
        "    (\"ai\", \"Argh me mateys\"),\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "# Create and run the chain\n",
        "chain = chat_prompt | chat | StrOutputParser()\n",
        "result = chain.invoke({\"text\": \"I love programming.\"})\n",
        "print(\"Pirate Translation Result:\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhJStTO8yueA",
        "outputId": "1884e515-77b7-441d-94c4-87d41b004136"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pirate Translation Result:\n",
            "Arrr, I be lovin' me some programming, aye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# Create our examples\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"What's the weather like?\",\n",
        "        \"answer\": \"It's raining cats and dogs, better bring an umbrella!\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How old are you?\",\n",
        "        \"answer\": \"Age is just a number, but I'm timeless.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create an example template\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "# Create a prompt example from above template\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "# Create the prefix and suffix\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "assistant. The assistant is known for its humor and wit, providing\n",
        "entertaining and amusing responses to users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "# Create the few-shot prompt template\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# Create and run the chain\n",
        "chain = few_shot_prompt_template | chat | StrOutputParser()\n",
        "result2 = chain.invoke({\"query\": \"What's the secret to happiness?\"})\n",
        "print(\"Few-Shot Humor Result:\")\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89om1qAyuY7",
        "outputId": "21c7987b-c5f1-4a01-883d-b93fe2bbd275"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot Humor Result:\n",
            "The secret to happiness? Easy—find the joy in the little things, like perfectly toasted bread or a good pun. And remember, if all else fails, chocolate is a pretty reliable backup plan!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
        "\n",
        "# Define examples for antonyms\n",
        "examples_antonyms = [\n",
        "    {\"word\": \"happy\", \"antonym\": \"sad\"},\n",
        "    {\"word\": \"tall\", \"antonym\": \"short\"},\n",
        "    {\"word\": \"energetic\", \"antonym\": \"lethargic\"},\n",
        "    {\"word\": \"sunny\", \"antonym\": \"gloomy\"},\n",
        "    {\"word\": \"windy\", \"antonym\": \"calm\"},\n",
        "]\n",
        "\n",
        "# Create example template\n",
        "example_template_antonyms = \"\"\"\n",
        "Word: {word}\n",
        "Antonym: {antonym}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt_antonyms = PromptTemplate(\n",
        "    input_variables=[\"word\", \"antonym\"],\n",
        "    template=example_template_antonyms\n",
        ")\n",
        "\n",
        "# Create the example selector\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples_antonyms,\n",
        "    example_prompt=example_prompt_antonyms,\n",
        "    max_length=25,\n",
        ")\n",
        "\n",
        "# Create dynamic prompt\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt_antonyms,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Word: {input}\\nAntonym:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\",\n",
        ")\n",
        "\n",
        "# Test with different inputs\n",
        "print(\"Length-Based Example Selector Results:\")\n",
        "print(\"Short input:\")\n",
        "print(dynamic_prompt.format(input=\"big\"))\n",
        "print(\"\\nLong input:\")\n",
        "print(dynamic_prompt.format(input=\"extremely sophisticated\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiKZ158gyuWO",
        "outputId": "e3da8255-6311-4188-f9d8-e8c5a1e3fc5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length-Based Example Selector Results:\n",
            "Short input:\n",
            "Give the antonym of every input\n",
            "\n",
            "Word: happy\n",
            "Antonym: sad\n",
            "\n",
            "\n",
            "Word: tall\n",
            "Antonym: short\n",
            "\n",
            "\n",
            "Word: energetic\n",
            "Antonym: lethargic\n",
            "\n",
            "\n",
            "Word: sunny\n",
            "Antonym: gloomy\n",
            "\n",
            "Word: big\n",
            "Antonym:\n",
            "\n",
            "Long input:\n",
            "Give the antonym of every input\n",
            "\n",
            "Word: happy\n",
            "Antonym: sad\n",
            "\n",
            "\n",
            "Word: tall\n",
            "Antonym: short\n",
            "\n",
            "\n",
            "Word: energetic\n",
            "Antonym: lethargic\n",
            "\n",
            "Word: extremely sophisticated\n",
            "Antonym:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mlxWzwS8tlKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9f85b1-63d3-43c3-865e-f56259bbc2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1:\n",
            "10°C → Output: 50°F\n",
            "\n",
            "Test 2:\n",
            "30°C → 86°F\n",
            "\n",
            "Test 3 (after adding new example):\n",
            "40°C → Output: 104°F\n",
            "\n",
            "==================================================\n",
            "COMPLETE TEMPERATURE CONVERSION EXAMPLE\n",
            "==================================================\n",
            "25°C → Input: 25°C  \n",
            "Output: 77°F\n",
            "--------------------\n",
            "15°C → Input: 15°C  \n",
            "Output: 59°F\n",
            "--------------------\n",
            "35°C → Input: 35°C  \n",
            "Output: 95°F\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        "from langchain_deeplake.vectorstores import DeeplakeVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# PromptTemplate\n",
        "example_prompt_temp = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")\n",
        "\n",
        "# Temperature conversion examples\n",
        "examples_temp = [\n",
        "    {\"input\": \"0°C\", \"output\": \"32°F\"},\n",
        "    {\"input\": \"10°C\", \"output\": \"50°F\"},\n",
        "    {\"input\": \"20°C\", \"output\": \"68°F\"},\n",
        "    {\"input\": \"30°C\", \"output\": \"86°F\"},\n",
        "    {\"input\": \"40°C\", \"output\": \"104°F\"},\n",
        "]\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Setup DeepLake dataset\n",
        "my_activeloop_org_id = \"anais\"  # TODO: Replace with your org ID\n",
        "my_activeloop_dataset_name = \"langchain_course_fewshot_selector\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "\n",
        "# Create SemanticSimilarityExampleSelector using DeeplakeVectorStore\n",
        "example_selector_semantic = SemanticSimilarityExampleSelector.from_examples(\n",
        "    examples_temp,\n",
        "    embeddings,\n",
        "    DeeplakeVectorStore,\n",
        "    k=1,\n",
        "    dataset_path=dataset_path,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "# FewShotPromptTemplate\n",
        "similar_prompt = FewShotPromptTemplate(\n",
        "    example_selector=example_selector_semantic,\n",
        "    example_prompt=example_prompt_temp,\n",
        "    prefix=\"Convert the temperature from Celsius to Fahrenheit\",\n",
        "    suffix=\"Input: {temperature}\\nOutput:\",\n",
        "    input_variables=[\"temperature\"],\n",
        ")\n",
        "\n",
        "# Test the similar_prompt with different inputs\n",
        "print(\"Test 1:\")\n",
        "temp_result1 = (similar_prompt | chat | StrOutputParser()).invoke({\"temperature\": \"10°C\"})\n",
        "print(f\"10°C → {temp_result1}\")\n",
        "\n",
        "print(\"\\nTest 2:\")\n",
        "temp_result2 = (similar_prompt | chat | StrOutputParser()).invoke({\"temperature\": \"30°C\"})\n",
        "print(f\"30°C → {temp_result2}\")\n",
        "\n",
        "# Add a new example to the SemanticSimilarityExampleSelector\n",
        "similar_prompt.example_selector.add_example({\"input\": \"50°C\", \"output\": \"122°F\"})\n",
        "print(\"\\nTest 3 (after adding new example):\")\n",
        "temp_result3 = (similar_prompt | chat | StrOutputParser()).invoke({\"temperature\": \"40°C\"})\n",
        "print(f\"40°C → {temp_result3}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 )\n",
        "\n",
        "# DeeplakeVectorStore directly for more control\n",
        "advanced_vectorstore = DeeplakeVectorStore(\n",
        "    dataset_path=f\"hub://{my_activeloop_org_id}/advanced_examples\",\n",
        "    embedding_function=embeddings,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "\n",
        "# Chain for temperature conversion\n",
        "temp_chain = similar_prompt | chat | StrOutputParser()\n",
        "\n",
        "print(\"COMPLETE TEMPERATURE CONVERSION EXAMPLE\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Test the complete chain\n",
        "test_temps = [\"25°C\", \"15°C\", \"35°C\"]\n",
        "for temp in test_temps:\n",
        "    result = temp_chain.invoke({\"temperature\": temp})\n",
        "    print(f\"{temp} → {result}\")\n",
        "    print(\"-\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltVBqpx0M0pV"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}