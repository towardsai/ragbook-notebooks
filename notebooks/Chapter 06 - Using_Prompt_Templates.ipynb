{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2006%20-%20Using_Prompt_Templates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "STjlSS-7kCoz"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain==0.3.26 langchain-openai==0.3.23 langchain-core==0.3.66"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XsV8LDNckFNY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"]=\"OPENAI_API_KEY\"\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"]= userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Prompt Template Example\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "template = \"\"\"Answer the question based on the context below. If the\n",
        "question cannot be answered using the information provided, answer\n",
        "with \"I don't know\".\n",
        "Context: Quantum computing is an emerging field that leverages quantum mechanics to solve complex problems faster than classical computers.\n",
        "...\n",
        "Question: {query}\n",
        "Answer: \"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# Create the chain for the prompt\n",
        "chain = prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Set the query you want to ask\n",
        "input_data = {\"query\": \"What is the main advantage of quantum computing over classical computing?\"}\n",
        "\n",
        "# Run the chain to get the AI-generated answer\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "print(\"Question:\", input_data[\"query\"])\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKzRJVBYsnvv",
        "outputId": "ee0d54d1-2a95-463b-c48a-1c56748b8bab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the main advantage of quantum computing over classical computing?\n",
            "Answer: The main advantage of quantum computing over classical computing is its ability to solve complex problems faster by leveraging quantum mechanics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-Shot Prompt Template Example\n",
        "from langchain_core.prompts import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n",
        "    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n",
        "    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "Animal: {animal}\n",
        "Habitat: {habitat}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"animal\", \"habitat\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Identify the habitat of the given animal\",\n",
        "    suffix=\"Animal: {input}\\nHabitat:\",\n",
        "    input_variables=[\"input\"],\n",
        "    example_separator=\"\\n\\n\",\n",
        ")\n",
        "\n",
        "# Create the chain for the dynamic_prompt\n",
        "chain = dynamic_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain with input_data\n",
        "input_data = {\"input\": \"tiger\"}\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxbBl7v8svjp",
        "outputId": "3c7a25d5-e9a8-4445-94a5-6a595219ebcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Animal: tiger  \n",
            "Habitat: tropical rainforests, grasslands, and mangrove swamps (primarily in Asia)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save prompt template\n",
        "prompt_template.save(\"awesome_prompt.json\")\n",
        "\n",
        "# Load prompt template\n",
        "from langchain_core.prompts import load_prompt\n",
        "loaded_prompt = load_prompt(\"awesome_prompt.json\")"
      ],
      "metadata": {
        "id": "xERi6IaDs49j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced Few-Shot with Personality\n",
        "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Cell 7: Sarcastic AI Assistant Example\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How do I become a better programmer?\",\n",
        "        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n",
        "    }, {\n",
        "        \"query\": \"Why is the sky blue?\",\n",
        "        \"answer\": \"It's nature's way of preventing eye strain.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "prefix = \"\"\"The following are excerpts from conversations with an AI\n",
        "assistant. The assistant is typically sarcastic and witty, producing\n",
        "creative and funny responses to users' questions. Here are some\n",
        "examples:\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\\n\"\n",
        ")\n",
        "\n",
        "# Create the chain for the few_shot_prompt_template\n",
        "chain = few_shot_prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain with input_data\n",
        "input_data = {\"query\": \"How can I learn quantum computing?\"}\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh7m-Lrll0af",
        "outputId": "caf95ac6-e7a8-4733-f19e-2a4d40539dbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Easy! Just build a tiny particle accelerator in your basement, then politely ask electrons to behave. Or, you know, start with some online courses and quantum mechanics basicsâ€”less radiation, more brain power.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extended examples list\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How do you feel today?\",\n",
        "        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n",
        "    }, {\n",
        "        \"query\": \"What is the speed of light?\",\n",
        "        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n",
        "    }, {\n",
        "        \"query\": \"What is a quantum computer?\",\n",
        "        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n",
        "    }, {\n",
        "        \"query\": \"Who invented the telephone?\",\n",
        "        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n",
        "    }, {\n",
        "        \"query\": \"What programming language is best for AI development?\",\n",
        "        \"answer\": \"Python, because it's the only snake that won't bite.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the capital of France?\",\n",
        "        \"answer\": \"Paris, the city of love and baguettes.\"\n",
        "    }, {\n",
        "        \"query\": \"What is photosynthesis?\",\n",
        "        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n",
        "    }, {\n",
        "        \"query\": \"What is the tallest mountain on Earth?\",\n",
        "        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the most abundant element in the universe?\",\n",
        "        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the largest mammal on Earth?\",\n",
        "        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the fastest land animal?\",\n",
        "        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the square root of 144?\",\n",
        "        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n",
        "    }, {\n",
        "        \"query\": \"What is the average temperature on Mars?\",\n",
        "        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "EoGpL3Nrl0X6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
        "\n",
        "# Use the correct example_prompt from Cell 7 (query/answer format)\n",
        "query_answer_example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=\"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "example_selector = LengthBasedExampleSelector(\n",
        "    examples=examples,\n",
        "    example_prompt=query_answer_example_prompt,\n",
        "    max_length=100\n",
        ")"
      ],
      "metadata": {
        "id": "fSaWipRPl0VQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic prompt template with example selector\n",
        "dynamic_prompt_template = FewShotPromptTemplate(\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=query_answer_example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "7x7sq6_Cp-5p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the dynamic prompt template\n",
        "# Create the chain for the dynamic_prompt_template\n",
        "chain = dynamic_prompt_template | llm | StrOutputParser()\n",
        "\n",
        "# Run the chain with input_data\n",
        "input_data = {\"query\": \"Who invented the telephone?\"}\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o414eEz-rEyV",
        "outputId": "d44dd903-e04b-4cc8-d926-80379e225909"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexander Graham Bell, the original 'ringmaster' who made sure we could all stop yelling across the room!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xppxUhn2l0Px"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}