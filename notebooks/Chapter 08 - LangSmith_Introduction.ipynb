{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2008%20-%20LangSmith_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.26 langchain-openai==0.3.23 langchain-community==0.3.26 langchain-core==0.3.66 openai==1.92.0 tiktoken==0.8.0 cohere==5.15.0 deeplake==4.2.11 langchain-deeplake==0.1.0 langchainhub==0.1.21"
      ],
      "metadata": {
        "id": "0LOMxQvMe5rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
        "# os.environ[\"ACTIVELOOP_TOKEN\"] = \"<YOUR_ACTIVELOOP_KEY>\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = \"<YOUR_LANGSMITH_API_KEY\"\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ACTIVELOOP_TOKEN\"] = userdata.get('ACTIVELOOP_TOKEN')\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = userdata.get('LangSmith_API_Key')\n",
        "os.environ[\"USER_AGENT\"] = \"LangSmith-Introduction\""
      ],
      "metadata": {
        "id": "qDLV03Dn0FjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load docs\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "data = loader.load()\n",
        "len( data )"
      ],
      "metadata": {
        "id": "ngpAq3Wse8uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "len( all_splits )"
      ],
      "metadata": {
        "id": "wP6xmZWIgQnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store splits\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_deeplake import DeeplakeVectorStore\n",
        "\n",
        "my_activeloop_org_id = \"\" # TODO: use your organization id here\n",
        "vectorstore = DeeplakeVectorStore.from_documents(\n",
        "    all_splits,\n",
        "    dataset_path=f\"hub://{my_activeloop_org_id}/langsmith_intro\",\n",
        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
        "    overwrite=True\n",
        "    )"
      ],
      "metadata": {
        "id": "Rxq2-2FagVww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "B3geETF5P2Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "client = Client()\n",
        "prompt = client.pull_prompt(\"rlm/rag-prompt\")\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "PRCbNMOpcOd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langsmith import Client\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "rag_chain = (\n",
        "    {\n",
        "        \"context\": retriever,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# Usage\n",
        "question = \"What are the approaches to Task Decomposition?\"\n",
        "result = rag_chain.invoke(question)\n",
        "print(\"Answer:\", result.content)"
      ],
      "metadata": {
        "id": "yPDlbSN4dU8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}