{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2008%20-%20Mastering_Advanced_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iSIIb6ey0POS"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index==0.12.43 deeplake==4.2.10 openai==1.92.0 cohere==5.15.0 llama-index-vector-stores-deeplake==0.3.3 llama-index-llms-openai==0.4.7 llama-index-postprocessor-cohere-rerank==0.4.0 jedi==0.19.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
        "# os.environ['ACTIVELOOP_TOKEN'] = '<YOUR_ACTIVELOOP_API_KEY>'\n",
        "# os.environ['COHERE_API_KEY'] = '<YOUR_COHERE_API_KEY>'\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['ACTIVELOOP_TOKEN'] = userdata.get('ACTIVELOOP_TOKEN')\n",
        "os.environ['COHERE_API_KEY'] = userdata.get('COHERE_API_KEY')"
      ],
      "metadata": {
        "id": "Ul1SFfON0TD1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p './paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O './paul_graham/paul_graham_essay.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7rXjNi00bWW",
        "outputId": "53777a88-db3d-4e9b-80ef-50a797fc1bdd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-25 02:40:18--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2026-01-25 02:40:19 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# Configure Settings (replaces ServiceContext)\n",
        "# Set up global settings\n",
        "Settings.llm = OpenAI(model=\"gpt-4.1-mini\", temperature=0.0)\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 50"
      ],
      "metadata": {
        "id": "0fVProCcNGO8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./paul_graham\").load_data()"
      ],
      "metadata": {
        "id": "C1Q0cMtj0kOs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 64\n",
        "\n",
        "node_parser = Settings.node_parser\n",
        "\n",
        "nodes = node_parser.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "MYUxH5fsqTvr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "\n",
        "my_activeloop_org_id = \"\" # TODO: use your organization id here\n",
        "my_activeloop_dataset_name = \"LlamaIndex_paulgraham_essay\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\" # Corrected prefix from hub:// to al://\n",
        "\n",
        "# Create an index over the documnts\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)"
      ],
      "metadata": {
        "id": "96K3MP511gh7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import StorageContext\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "storage_context.docstore.add_documents(nodes)"
      ],
      "metadata": {
        "id": "FaH-fN_b1PQo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
      ],
      "metadata": {
        "id": "JBGiu_3j17mX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(streaming=True, similarity_top_k=10)"
      ],
      "metadata": {
        "id": "uOoF3OYa2a-q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "streaming_response = query_engine.query(\n",
        "    \"What does Paul Graham do?\",\n",
        ")\n",
        "streaming_response.print_response_stream()"
      ],
      "metadata": {
        "id": "QpbkU6GR2mUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b6c7dc-c49e-41c1-d19b-aac9e5500037"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paul Graham is an essayist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SubQuestion Query Engine"
      ],
      "metadata": {
        "id": "9l7VRFwBL3oS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(similarity_top_k=10)"
      ],
      "metadata": {
        "id": "semCwp2XMmXq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=query_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"pg_essay\",\n",
        "            description=\"Paul Graham essay on What I Worked On\",\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "query_engine = SubQuestionQueryEngine.from_defaults(\n",
        "    query_engine_tools=query_engine_tools,\n",
        "    use_async=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "PbYKvMGXtTgW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"How was Paul Grahams life different before, during, and after YC?\"\n",
        ")"
      ],
      "metadata": {
        "id": "rDRMYb9HMH7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05969f0-09f5-45fa-d027-08760f45b5b8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 3 sub questions.\n",
            "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What details does Paul Graham provide about his life before starting Y Combinator in his essay?\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: What experiences and challenges does Paul Graham describe during the time he was involved with Y Combinator?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: How does Paul Graham describe his life and activities after his involvement with Y Combinator?\n",
            "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] A: Paul Graham describes his life after his involvement with Y Combinator as focused on writing essays and thinking deeply about startups and related topics. He shifted from active startup involvement to sharing his insights and experiences through his essays, which have influenced many in the tech and startup communities.\n",
            "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: Paul Graham describes his background before starting Y Combinator by discussing his experiences as a programmer and writer. He mentions his work on various programming languages and his involvement in creating software. Additionally, he talks about his interest in startups and technology, as well as his efforts in writing essays that explore ideas related to entrepreneurship and innovation. These experiences and interests laid the foundation for his later work in founding Y Combinator.\n",
            "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] A: Paul Graham describes a range of experiences and challenges during his time with Y Combinator, including the intense effort required to select and support startups, the difficulties of mentoring young founders, and the constant need to adapt the program to better serve the needs of entrepreneurs. He highlights the challenge of balancing hands-on involvement with allowing startups the freedom to grow independently. Additionally, he reflects on the learning curve involved in understanding what makes startups succeed and the importance of creating an environment that fosters innovation and rapid iteration.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \">>> The final response:\\n\", response )"
      ],
      "metadata": {
        "id": "pRvnUf7zMLBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f33ff3e-37be-423b-e759-707775e44f10"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> The final response:\n",
            " Before starting Y Combinator, Paul Graham was primarily engaged as a programmer and writer, working on programming languages and software development while cultivating an interest in startups and technology. During his time with Y Combinator, his life involved intense efforts in selecting and supporting startups, mentoring founders, and continuously adapting the program to better meet entrepreneurs' needs, balancing hands-on guidance with allowing startups independence. After his involvement with Y Combinator, he shifted his focus to writing essays and reflecting deeply on startups and related topics, sharing his insights with the broader tech and startup communities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cohere Rerank"
      ],
      "metadata": {
        "id": "t8jeNI3Igwqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "# Get your cohere API key on: www.cohere.com\n",
        "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
        "\n",
        "# Example query and passages\n",
        "query = \"What is the capital of the United States?\"\n",
        "documents = [\n",
        "   \"Carson City is the capital city of the American state of Nevada. At the  2010 United States Census, Carson City had a population of 55,274.\",\n",
        "   \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
        "   \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
        "   \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
        "   \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
        "   \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\"\n",
        "   ]"
      ],
      "metadata": {
        "id": "mVJOtIHQgxlf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query, documents=documents, top_n=3, model='rerank-english-v3.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "\n",
        "\n",
        "for idx, r in enumerate(results.results):\n",
        "    print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "    print(f\"Relevance Score: {r.relevance_score:.5f}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "O0nOLQmmg3yY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84290dc4-9581-4a8a-ba99-631e9334e03f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 3\n",
            "Relevance Score: 0.99907\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 4\n",
            "Relevance Score: 0.77798\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 1\n",
            "Relevance Score: 0.08882\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cohere in LlamaIndex"
      ],
      "metadata": {
        "id": "bifEKCqihBBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
        "\n",
        "cohere_rerank = CohereRerank(api_key=os.environ['COHERE_API_KEY'], top_n=10)"
      ],
      "metadata": {
        "id": "AtRoHfgClgqS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(\n",
        "    similarity_top_k=10,\n",
        "    node_postprocessors=[cohere_rerank],\n",
        ")"
      ],
      "metadata": {
        "id": "qpU4Qwo3lgns"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\n",
        "    \"What did Sam Altman do in this essay?\",\n",
        ")\n",
        "print( response )"
      ],
      "metadata": {
        "id": "9uvVyML8lgkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3b5a1b-7e98-47e5-bded-a96e44c23dbb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The essay discusses Sam Altman's role as a key figure in the startup and technology world, highlighting his leadership and influence in fostering innovation and supporting new ventures. It portrays him as someone who has contributed significantly to the growth and development of startups, often emphasizing his ability to identify promising ideas and help turn them into successful companies.\n"
          ]
        }
      ]
    }
  ]
}