{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2009%20-%20LlamaIndex_RAG_AGENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index==0.12.43 deeplake==4.2.10 openai==1.92.0 llama-index-vector-stores-deeplake==0.3.3 llama-index-llms-openai==0.4.7 jedi==0.19.2"
      ],
      "metadata": {
        "id": "oLsz4honE_jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
        "# os.environ['ACTIVELOOP_TOKEN'] = '<YOUR_ACTIVELOOP_API_KEY>'\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['ACTIVELOOP_TOKEN'] = userdata.get('ACTIVELOOP_TOKEN')"
      ],
      "metadata": {
        "id": "Uh_M0Z0FFJPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Indexes"
      ],
      "metadata": {
        "id": "e4xCp6-mN3xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/1k/'\n",
        "!wget 'https://github.com/idontcalculate/data-repo/blob/main/machine_to_end_war.txt' -O './data/1k/tesla.txt'\n",
        "!wget 'https://github.com/idontcalculate/data-repo/blob/main/prodigal_chapter10.txt' -O './data/1k/web.txt'"
      ],
      "metadata": {
        "id": "mE86KzdvOPgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From VectorStore"
      ],
      "metadata": {
        "id": "Bj1f44flf-G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import updated LlamaIndex modules\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, Settings\n",
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.tools import FunctionTool, QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.agent.workflow import FunctionAgent"
      ],
      "metadata": {
        "id": "ze0sL25ef9iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure global settings\n",
        "Settings.llm = OpenAI(model=\"gpt-4.1-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "HAnH412gf9fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Tesla documents and create vector store index\n",
        "tesla_docs = SimpleDirectoryReader(input_files=[\"./data/1k/tesla.txt\"]).load_data()\n",
        "\n",
        "# Setup DeepLake vector store\n",
        "my_activeloop_org_id = \"anais\" # TODO : replace with your org_id\n",
        "my_activeloop_dataset_name = \"LlamaIndex_tesla_predictions\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "# Create vector store and storage context\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# Create index from documents\n",
        "tesla_index = VectorStoreIndex.from_documents(tesla_docs, storage_context=storage_context)"
      ],
      "metadata": {
        "id": "tteqteS-gxl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Local Index"
      ],
      "metadata": {
        "id": "9q971Fs5hbeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and create local index for webtext\n",
        "webtext_docs = SimpleDirectoryReader(input_files=[\"./data/1k/web.txt\"]).load_data()\n",
        "\n",
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "try:\n",
        "    # Try to load the index if it exists\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage/webtext\")\n",
        "    webtext_index = load_index_from_storage(storage_context)\n",
        "    print(\"Loaded the pre-computed index.\")\n",
        "except:\n",
        "    # Otherwise, generate the index\n",
        "    webtext_index = VectorStoreIndex.from_documents(webtext_docs)\n",
        "    webtext_index.storage_context.persist(persist_dir=\"./storage/webtext\")\n",
        "    print(\"Generated the index.\")"
      ],
      "metadata": {
        "id": "pUH_yneJg7re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Query Enginges"
      ],
      "metadata": {
        "id": "XPSztz6sgLR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tesla_query_engine = tesla_index.as_query_engine(similarity_top_k=3)\n",
        "webtext_query_engine = webtext_index.as_query_engine(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "qmEvngfef9NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Tools"
      ],
      "metadata": {
        "id": "NwunasqRgPCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine_tools = [\n",
        "    QueryEngineTool(\n",
        "        query_engine=tesla_query_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"tesla_1k\",\n",
        "            description=(\n",
        "                \"Provides information about Tesla's statements that refers to future times and predictions. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=webtext_query_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"webtext_1k\",\n",
        "            description=(\n",
        "                \"Provides information about tesla's life and biographical data. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "YCQaExCaf9Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Agent"
      ],
      "metadata": {
        "id": "nrsShMczgTdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FunctionAgent\n",
        "agent = FunctionAgent(\n",
        "    tools=query_engine_tools,\n",
        "    llm=Settings.llm,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "aJsJMHNRf9Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive chat with the agent\n",
        "import asyncio\n",
        "\n",
        "async def chat_with_agent():\n",
        "    \"\"\"Async function to interact with the agent\"\"\"\n",
        "    print(\"Agent is ready! Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = await agent.run(user_input)\n",
        "            print(f\"Agent: {response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "qP7aGx02f9DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To stop this chat enter quit in the the chat bot\n",
        "await chat_with_agent()"
      ],
      "metadata": {
        "id": "SuWz2YjeiU9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents with Tools"
      ],
      "metadata": {
        "id": "lZYW9kKZgZYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "# Create function tools using the updated API\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "\n",
        "# Create agent with function tools\n",
        "function_tools = [multiply_tool, add_tool]\n",
        "\n",
        "math_agent = FunctionAgent(\n",
        "    tools=function_tools,\n",
        "    llm=Settings.llm,\n",
        "    verbose=False,\n",
        "    system_prompt=\"You are a helpful math assistant. Use the provided tools to perform calculations.\"\n",
        ")"
      ],
      "metadata": {
        "id": "XAP_7rylgVUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the math agent\n",
        "async def test_math_agent():\n",
        "    \"\"\"Test the math agent with some calculations\"\"\"\n",
        "\n",
        "    # Test multiplication\n",
        "    response1 = await math_agent.run(\"What's 12 multiplied by 22? Make sure to use tools\")\n",
        "    print(f\"Multiplication result: {response1}\")\n",
        "\n",
        "    # Test addition\n",
        "    response2 = await math_agent.run(\"What is 5 + 2?\")\n",
        "    print(f\"Addition result: {response2}\")\n",
        "\n",
        "# Run the test\n",
        "await test_math_agent()"
      ],
      "metadata": {
        "id": "7DgSrvCUgVPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced agent with both query engines and math tools\n",
        "all_tools = query_engine_tools + function_tools\n",
        "\n",
        "enhanced_agent = FunctionAgent(\n",
        "    tools=all_tools,\n",
        "    llm=Settings.llm,\n",
        "    verbose=False,\n",
        "    system_prompt=(\n",
        "        \"You are an AI assistant that can answer questions about Tesla and perform mathematical calculations. \"\n",
        "        \"Use the tesla_1k tool for questions about Tesla's future predictions and statements. \"\n",
        "        \"Use the webtext_1k tool for questions about Tesla's biographical information. \"\n",
        "        \"Use the math tools (add, multiply) for mathematical calculations.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Multi-tool usage\n",
        "async def demo_enhanced_agent():\n",
        "    \"\"\"Demonstrate the enhanced agent with multiple tools\"\"\"\n",
        "\n",
        "    queries = [\n",
        "        \"What are Tesla's predictions for the future?\",\n",
        "        \"Tell me about Tesla's early life\",\n",
        "        \"Calculate 15 * 8 + 25\"\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        print(f\"\\nUser: {query}\")\n",
        "        response = await enhanced_agent.run(query)\n",
        "        print(f\"Agent: {response}\")\n",
        "\n",
        "# Run the demo\n",
        "await demo_enhanced_agent()"
      ],
      "metadata": {
        "id": "zSXqbSeOgVKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWWgyBeYgVHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}