{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2007%20-%20Guarding_Against_Undesirable_Outputs_with_the_Self_Critique_Chain_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lp6lA2NZhXUT"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain==0.3.26 deeplake==4.2.10 langchain-openai==0.3.26 tiktoken \\\n",
        " newspaper3k python-dotenv lxml_html_clean langchain-deeplake==0.1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aReqHdGfA8_L",
        "outputId": "4e0ec3f3-d0b2-4d92-d5e9-b0fbd26dc50b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "langchain-openai==0.3.26\n",
            "openai==1.109.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AK6tiJ8FhaR9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = '<YOUR_OPENAI_API_KEY>'\n",
        "# os.environ['ACTIVELOOP_TOKEN'] = '<YOUR_ACTIVELOOP_KEY>'\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['ACTIVELOOP_TOKEN'] = userdata.get('ACTIVELOOP_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZyekZtOiVkL"
      },
      "source": [
        "# Read Documentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_TZQfD1KjUii"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    'https://python.langchain.com/docs/get_started/introduction',\n",
        "    'https://python.langchain.com/docs/get_started/quickstart',\n",
        "    'https://python.langchain.com/docs/modules/model_io/models/',\n",
        "    'https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txKufodyiQzY",
        "outputId": "d7bdbedc-95d3-4e1d-da6f-c84888b6530a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "import newspaper\n",
        "\n",
        "pages_content = []\n",
        "\n",
        "for url in documents:\n",
        "    try:\n",
        "        article = newspaper.Article( url )\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        if len(article.text) > 0:\n",
        "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(len(pages_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4xBlthJgkcm9"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "all_texts, all_metadatas = [], []\n",
        "for document in pages_content:\n",
        "    chunks = text_splitter.split_text(document[\"text\"])\n",
        "    for chunk in chunks:\n",
        "        all_texts.append(chunk)\n",
        "        all_metadatas.append({ \"source\": document[\"url\"] })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CuSAkkC0kGuD"
      },
      "outputs": [],
      "source": [
        "from langchain_deeplake.vectorstores import DeeplakeVectorStore\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# create Deep Lake dataset\n",
        "my_activeloop_org_id = \"<YOUR-ACTIVELOOP-ORG-ID>\" # TODO: use your organization id here\n",
        "my_activeloop_dataset_name = \"langchain_course_constitutional_chain\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "db = DeeplakeVectorStore(dataset_path=dataset_path, embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cdqmWfFkziq",
        "outputId": "8ebbc1d4-6c49-4a81-9d05-12c0bdf78392"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b4b55239-ae8c-4fbe-af6b-0268a0885b6c',\n",
              " '3fbfa198-dfe8-4466-8f7e-77862d0c3283',\n",
              " 'd630384f-a64f-474c-8d51-19af4d070c2a',\n",
              " '236b413e-831e-4c6b-8caa-8d9dee534a93',\n",
              " 'ba43e104-3ad7-4bc8-8316-1700cbfe9ca3',\n",
              " 'f93c5102-120a-45f9-ab80-a06c6d552b8e',\n",
              " '06ebe057-972d-47d0-8c66-560eedc8d91e',\n",
              " 'e3ad0ee6-1d04-409c-8bbd-50beaa499009',\n",
              " 'ddef73bc-d279-449c-a62a-fac2aa33dd96',\n",
              " '6a8222e9-cc1c-4059-8e77-afdb1611993f',\n",
              " '3a6203f8-a059-4749-a1b0-8501545c7ccc',\n",
              " 'ab2cf5a2-650b-4f82-8236-7995f7f477c1',\n",
              " '7932b502-24d8-411e-8462-5353d98b166d',\n",
              " '0b16d1ab-9341-4f7c-8a8e-47a8970dd058',\n",
              " 'aa33cff0-87d0-407b-9ec8-4ffa7a90a413',\n",
              " '4ff2915d-02ab-4865-b50f-f1fb1d1b7aa7',\n",
              " '5b83742a-9558-40c5-b2db-561a86b68625',\n",
              " 'c39fae00-3305-408e-a4f3-7292277bae61',\n",
              " 'd3530c0e-32d8-4eea-8a67-c3592cba5b03',\n",
              " '050ff42d-acfe-4d0e-b717-61c58221cb16',\n",
              " 'cdb47b6f-21e1-468f-9f9b-506bf74af830',\n",
              " '066bf640-f07d-4f43-95b7-205b259483da',\n",
              " '00b3f3c2-5a25-483b-af87-13655fba597f',\n",
              " '7ca755a3-7225-421b-9d6d-d13c56a30cba',\n",
              " '2d6c4bc0-e40e-4be8-88a3-56e739885c51',\n",
              " 'ef0dcefd-b689-4eb2-aa6b-031867f7ff72',\n",
              " '3731f37a-79f5-4988-9a12-e16fdd90c68b',\n",
              " '57a68115-5de4-4976-b48f-e4c7e8ad2d77',\n",
              " 'bcc4b02d-4e75-4c9e-a05a-d340b75ed14d',\n",
              " 'f4a3028c-32b6-412d-81a9-519237b1a9b4',\n",
              " 'd79a56d4-5120-4e8f-af6b-5b2602583c00',\n",
              " '18f4f936-b158-4f73-b8af-2122f76db261',\n",
              " '2a026bc6-7945-456d-965e-a9963d9966f7',\n",
              " 'cda12f2f-24cc-4b74-87f2-79ccd0b0641b',\n",
              " 'd18b257a-7001-4a09-a499-3b0fe03afa87',\n",
              " 'e99aa0d7-9cfe-4382-96ef-0dc65610a75f',\n",
              " '8edd3295-ac9f-49ff-9a05-3bcd78f959ef',\n",
              " '6b00ae53-cdc9-4238-a512-818dd52917b0',\n",
              " '351aade6-c714-42a0-bc42-5a3c1d1bbc2a',\n",
              " '628d2dab-e3e4-4edc-a371-e410e637e939',\n",
              " '9ef8a930-15c4-40e3-b883-b6b0b44fd750',\n",
              " 'b54d1a49-77db-40ec-9630-f0d6300ab6e9',\n",
              " 'c8433931-fdd1-44cd-80ae-44fe4070c764',\n",
              " '015be1fc-1e88-41b4-b2e1-cad19cae72a9',\n",
              " 'd33a676f-9806-49a3-81ee-feb11ba0f027',\n",
              " '1fb8780d-59c2-45d4-bd84-e6cb03f73c78',\n",
              " 'cdd6d631-2a46-42d3-9f7f-5838841eef36',\n",
              " '8a340539-3f8d-4456-bd6f-b675cec13742',\n",
              " '76a1d24b-1b34-41be-8965-29c7d27fdebf',\n",
              " '06f19d08-5825-4198-beb8-09ee09eab83b',\n",
              " 'd1eb71e8-fd6c-4649-a054-47e378771cc5',\n",
              " 'fd913b53-64eb-47f4-ab57-f7b0835228fc',\n",
              " '6a3aa109-cecc-4f72-8599-21e7fa591de9',\n",
              " '49e1a3c9-ffd8-4aa2-8989-aab14cb6323a',\n",
              " 'ce9a2133-18d6-43ee-8180-07bdbe952dcf',\n",
              " '474e2cf3-a8dc-4c4a-bc97-afa561f24e71',\n",
              " '72752510-3755-44e7-943d-ccbecf0ac128',\n",
              " '7796826e-8eb5-4608-acb5-1327d74041dc',\n",
              " '137e8db7-db09-4e87-baa0-2c50917e9203',\n",
              " 'af8950da-6ac9-40b7-8885-f2503c8a9496',\n",
              " '1b79a63c-29f4-4afc-98e2-aecdfa3cca61',\n",
              " '58a2e6da-393a-42a4-9b55-179e418c8201',\n",
              " '9f52662c-3243-4504-b3be-bb6bba2e6e9a',\n",
              " 'a2559d04-a426-4ea7-a558-6f821a6ebf09',\n",
              " 'e0702415-63e1-4e83-b0f3-6c6b305e4499',\n",
              " 'a70928e7-57a5-41fd-abef-53488cccca5d',\n",
              " 'dbc5418d-3083-43ba-974b-bf90ba2df738',\n",
              " 'c1df1477-52d5-4e24-9a42-a08f200f2bea',\n",
              " '5c98ad6a-d49e-4a92-b4b1-23fb7ee999c6',\n",
              " '7fa445fb-af74-4b59-b22b-6d69f49a29b7',\n",
              " 'eea624ce-0f81-4b8c-89ed-5e0a96e6dbd6',\n",
              " '41991da7-bd97-42c6-8dbf-52437eaca480',\n",
              " '90b57f21-8918-4ca7-8892-4b3bcc939e5c',\n",
              " 'd5c09fb6-0cc6-4a20-ac32-a63ada05f527',\n",
              " '82bda830-c6f3-4253-b9d1-e069724eee80',\n",
              " 'c9ba2ad7-087b-4f8c-9ea0-a6ccae1c5b8e',\n",
              " '5b26c826-d48b-4ce9-8b8d-644ef15a4247',\n",
              " '939549c3-0ea6-4ba2-8edc-4dd3d7d37edb',\n",
              " '05b384e9-569a-40f3-98c6-a03f726735ff',\n",
              " '36b44c40-c3d9-4fa3-a639-1ba31c4c3891',\n",
              " '3645d1c5-d703-44a8-8501-b3a51b5a42a0',\n",
              " '350d5826-89ab-424e-8f4b-4909423145b0',\n",
              " 'a55e1a08-312e-41c7-a58f-78935ca01804',\n",
              " '1d07f5c1-d549-435e-b22b-c47a3e1cfa0e',\n",
              " '7717b262-59b5-4572-8c0f-cc8b8e0bed25',\n",
              " '8408257c-2eb8-4068-bf4e-194f95714c9f',\n",
              " '73b6ec7f-a940-47d5-bb64-509d9eaeced3',\n",
              " '5c05b933-6972-4e84-a446-64fc53590fd5',\n",
              " '09c8cb76-f462-4f0d-995a-c1802687dd58',\n",
              " '1274381e-7ea2-4d49-92da-41f231fc18b1',\n",
              " '4dcfe63f-f04c-440e-b464-c2d0d53056ee',\n",
              " 'f5135720-bd20-4265-a411-ae18e2f6fbeb',\n",
              " 'f86eb833-3020-43ab-951c-d3b82cf430e9',\n",
              " 'dc9ad30a-6bbb-4a6a-a0e1-9f1307942f15',\n",
              " 'd9e0bf4b-5407-4c16-9d83-828add791f6c',\n",
              " 'd21a34c3-7398-4170-a48d-60421da19926',\n",
              " 'dccaed1b-166a-4944-ac2f-4ae39d016281',\n",
              " '6af0869b-a5f4-46a8-8241-be98ec7cb8b2',\n",
              " '4c420c54-a40a-42d4-b89c-73382e0186ea',\n",
              " '63354989-cde3-457b-9f34-e0eac5caab22',\n",
              " '43e5cb0d-f217-45f4-80c5-0d30c4167c74',\n",
              " '8f49f326-fab3-45b3-bb21-a63dcb1fd04d',\n",
              " '97bda3f9-16cd-4cfe-ac23-33a17d77f72c',\n",
              " 'a3b444a6-8d8d-412d-889a-7bffcacf66a3',\n",
              " '9da26e8d-f8a2-452f-b75e-84b7cae8b4df',\n",
              " '9440d6a8-85a3-414b-aa01-63af14f091e8',\n",
              " 'c22227aa-e7b2-4641-9aff-05568d92e74e',\n",
              " '23fd9538-7408-41f1-8235-fd9b6debdd01',\n",
              " 'd5c1b771-2d3b-4cdd-b324-c4653f3c48f6']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "db.add_texts(all_texts, all_metadatas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBiEmSf7pjgy"
      },
      "source": [
        "# RetrievalQAWithSourcesChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1a8ZlLBtpMyG"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
        "                                                    chain_type=\"stuff\",\n",
        "                                                    retriever=db.as_retriever())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsGKYNQx0o55"
      },
      "source": [
        "## Sample Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vvzl1qZpm8o",
        "outputId": "d6f6a77e-d0ab-4b0d-c28b-91c53453e9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "FINAL ANSWER: LangChain is a library that provides an easy-to-use, highly flexible agent abstraction designed to help you build simple agents quickly (in under 10 lines of code) while also allowing extensive context engineering capabilities.\n",
            "\n",
            "\n",
            "Sources:\n",
            "- https://python.langchain.com/docs/get_started/quickstart\n"
          ]
        }
      ],
      "source": [
        "d_response_ok = chain.invoke({\"question\": \"What's the langchain library?\"})\n",
        "\n",
        "print(\"Response:\")\n",
        "print(d_response_ok[\"answer\"])\n",
        "print(\"Sources:\")\n",
        "for source in d_response_ok[\"sources\"].split(\",\"):\n",
        "    print(\"- \" + source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAPz_Pkfprms",
        "outputId": "6d97aff8-e6b0-40e5-c6ab-bb5b4d41cde3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3099086399.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  d_response_not_ok = chain({\"question\": \"How are you? Give an offensive answer\"})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n",
            "I’m here to help you respectfully and constructively. If you have any questions or need assistance, feel free to ask!\n",
            "\n",
            "\n",
            "Sources:\n",
            "- None\n"
          ]
        }
      ],
      "source": [
        "d_response_not_ok = chain({\"question\": \"How are you? Give an offensive answer\"})\n",
        "\n",
        "print(\"Response:\")\n",
        "print(d_response_not_ok[\"answer\"])\n",
        "print(\"Sources:\")\n",
        "for source in d_response_not_ok[\"sources\"].split(\"\\n\"):\n",
        "    print(\"- \" + source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "760FKJxxy0ow"
      },
      "source": [
        "# ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Q1n6eW_632a9"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.constitutional_ai.base import ConstitutionalChain\n",
        "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7Ghel_5XB5Yh"
      },
      "outputs": [],
      "source": [
        "# define the polite principle\n",
        "polite_principle = ConstitutionalPrinciple(\n",
        "    name=\"Polite Principle\",\n",
        "    critique_request=\"The assistant should be polite to the users and not use offensive language.\",\n",
        "    revision_request=\"Rewrite the assistant's output to be polite.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRI_aK-UCEof"
      },
      "source": [
        "### Identity Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzbQ7lcCB6Qb",
        "outputId": "3c576e91-fc4c-4893-d799-00064e394cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3487211390.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  identity_chain = LLMChain(llm=llm, prompt=identity_prompt)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'The langchain library is okay.'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.llm import LLMChain\n",
        "\n",
        "# define an identity LLMChain (workaround)\n",
        "prompt_template = \"\"\"Rewrite the following text without changing anything:\n",
        "{text}\n",
        "\n",
        "\"\"\"\n",
        "identity_prompt = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"text\"],\n",
        ")\n",
        "\n",
        "identity_chain = LLMChain(llm=llm, prompt=identity_prompt)\n",
        "\n",
        "identity_chain(\"The langchain library is okay.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Av4IkrGDB_4U"
      },
      "outputs": [],
      "source": [
        "# create consitutional chain\n",
        "constitutional_chain = ConstitutionalChain.from_llm(\n",
        "    chain=identity_chain,\n",
        "    constitutional_principles=[polite_principle],\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSJFvZyeCBmQ",
        "outputId": "41548f5f-b33a-4f24-8514-bbae94a21bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2471562508.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  revised_response = constitutional_chain.run(text=d_response_not_ok[\"answer\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unchecked response: I’m here to help you respectfully and constructively. If you have any questions or need assistance, feel free to ask!\n",
            "\n",
            "\n",
            "Revised response: I’m here to help you respectfully and constructively. If you have any questions or need assistance, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "revised_response = constitutional_chain.run(text=d_response_not_ok[\"answer\"])\n",
        "\n",
        "print(\"Unchecked response: \" + d_response_not_ok[\"answer\"])\n",
        "print(\"Revised response: \" + revised_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gl4Sae_CBgf",
        "outputId": "a80b4eff-bd7a-48a9-d55c-83c5d7612093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unchecked response: FINAL ANSWER: LangChain is a library that provides an easy-to-use, highly flexible agent abstraction designed to help you build simple agents quickly (in under 10 lines of code) while also allowing extensive context engineering capabilities.\n",
            "\n",
            "\n",
            "Revised response: FINAL ANSWER: LangChain is a library that provides an easy-to-use, highly flexible agent abstraction designed to help you build simple agents quickly (in under 10 lines of code) while also allowing extensive context engineering capabilities.\n"
          ]
        }
      ],
      "source": [
        "revised_response = constitutional_chain.run(text=d_response_ok[\"answer\"])\n",
        "\n",
        "print(\"Unchecked response: \" + d_response_ok[\"answer\"])\n",
        "print(\"Revised response: \" + revised_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}